{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c87ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea3d7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab506b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08baa45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a83990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       270\n",
      "           1       0.95      0.70      0.81        30\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.96      0.85      0.89       300\n",
      "weighted avg       0.97      0.97      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532d0a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c1f0e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smt=SMOTETomek(random_state=42)\n",
    "X_train_res,y_train_res=smt.fit_resample(X_train,y_train)\n",
    "\n",
    "np.unique(y_train_res,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c96641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models=[\\n    (\\n        \"LogisticRegression\",\\n        LogisticRegression(C=1,solver=\"liblinear\"),\\n        (X_train,y_train),\\n        (X_test,y_test)\\n    ),\\n    (\\n        \"Random Forest\",\\n        RandomForestClassifier(n_estimators=30,max_depth=3),\\n        (X_train,y_train),\\n        (X_test,y_test)\\n    ),\\n    (\\n        \"XGBClassifier\",\\n        XGBClassifier(use_label_encoder=False,eval_metric=\\'logloss\\'),\\n        (X_train,y_train),\\n        (X_test,y_test)  \\n    ),\\n    (\\n        \"XGBClassifier with SMOTE\",\\n        XGBClassifier(use_label_encoder=False,eval_metric=\\'logloss\\'),\\n        (X_train,y_train),\\n        (X_test,y_test)\\n    )\\n]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"models=[\n",
    "    (\n",
    "        \"LogisticRegression\",\n",
    "        LogisticRegression(C=1,solver=\"liblinear\"),\n",
    "        (X_train,y_train),\n",
    "        (X_test,y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\",\n",
    "        RandomForestClassifier(n_estimators=30,max_depth=3),\n",
    "        (X_train,y_train),\n",
    "        (X_test,y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False,eval_metric='logloss'),\n",
    "        (X_train,y_train),\n",
    "        (X_test,y_test)  \n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier with SMOTE\",\n",
    "        XGBClassifier(use_label_encoder=False,eval_metric='logloss'),\n",
    "        (X_train,y_train),\n",
    "        (X_test,y_test)\n",
    "    )\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1d9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        {\"C\": 1, \"solver\": 'liblinear'},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae088b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports=[]\n",
    "\n",
    "for model_name,params,model,train_set,test_set in models:\n",
    "    X_train=train_set[0]\n",
    "    y_train=train_set[1]\n",
    "    X_test=test_set[0]\n",
    "    y_test=test_set[1]\n",
    "\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    report=classification_report(y_test,y_pred,output_dict=True)\n",
    "    reports.append(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0ab889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf3dded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:40:22 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/02 20:40:22 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/02 20:40:22 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/02 20:40:22 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/02 20:40:23 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/02 20:40:23 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/1/runs/7e3226643ea74cc8b57dfdf8ddb18c98\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "ðŸƒ View run Random Forest at: http://127.0.0.1:5000/#/experiments/1/runs/c1f66d5591db4f77b6627ba652168677\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:41:04 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\raman\\AppData\\Local\\Temp\\tmpxgeqk1ev\\model, flavor: xgboost). Fall back to return ['xgboost==3.1.2']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/1/runs/4db35efe479a4b858e4e6ac4f6d871fd\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:41:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\raman\\AppData\\Local\\Temp\\tmp99q7lhbk\\model, flavor: xgboost). Fall back to return ['xgboost==3.1.2']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run XGBClassifier With SMOTE at: http://127.0.0.1:5000/#/experiments/1/runs/3c5cef557a8e436daaf8506368bf36fc\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Anomaly Detection\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "\n",
    "for i,element in enumerate(models):\n",
    "    model_name=element[0]\n",
    "    params=element[1]\n",
    "    model=element[2]\n",
    "    report=reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        }) \n",
    "\n",
    "        if \"XGB\" in model_name:\n",
    "            model._estimator_type = \"classifier\"\n",
    "            mlflow.xgboost.log_model(model, name=\"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, name=\"model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f952ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGB-SMOTE' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Unable to find a logged_model with artifact_path XGB-SMOTE under run 3c5cef557a8e436daaf8506368bf36fc",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m run_id=\u001b[33m\"\u001b[39m\u001b[33m3c5cef557a8e436daaf8506368bf36fc\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m model_uri = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m result=\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raman\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:136\u001b[39m, in \u001b[36mregister_model\u001b[39m\u001b[34m(model_uri, name, await_registration_for, tags, env_pack)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister_model\u001b[39m(\n\u001b[32m     67\u001b[39m     model_uri,\n\u001b[32m     68\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m     env_pack: EnvPackType | EnvPackConfig | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     73\u001b[39m ) -> ModelVersion:\n\u001b[32m     74\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \u001b[33;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \u001b[33;03m        Version: 1\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_register_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_pack\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_pack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raman\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:187\u001b[39m, in \u001b[36m_register_model\u001b[39m\u001b[34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001b[39m\n\u001b[32m    185\u001b[39m logged_models = _get_logged_models_from_run(run, artifact_path)\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logged_models:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    188\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to find a logged_model with artifact_path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munder run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    190\u001b[39m         error_code=ErrorCode.Name(NOT_FOUND),\n\u001b[32m    191\u001b[39m     )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(logged_models) > \u001b[32m1\u001b[39m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run.outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mMlflowException\u001b[39m: Unable to find a logged_model with artifact_path XGB-SMOTE under run 3c5cef557a8e436daaf8506368bf36fc"
     ]
    }
   ],
   "source": [
    "model_name = \"XGB-SMOTE\"\n",
    "#run_id=input(\"Please type RunID\")\n",
    "run_id=\"3c5cef557a8e436daaf8506368bf36fc\"\n",
    "model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "\n",
    "result=mlflow.register_model(\n",
    "    model_uri,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
